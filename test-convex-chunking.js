/**
 * Test script for Convex enhanced chunking functions
 * This script tests the actual Convex functions to ensure they work properly
 */

const { ConvexHttpClient } = require("convex/browser");

// Initialize Convex client
const client = new ConvexHttpClient(
  process.env.CONVEX_URL || "http://localhost:3210"
);

async function testEnhancedChunking() {
  console.log("ğŸš€ Testing Convex Enhanced Chunking Functions");
  console.log("=".repeat(50));

  try {
    // Test 1: Compare chunking strategies
    console.log("\nğŸ“Š Test 1: Comparing Chunking Strategies");
    console.log("-".repeat(40));

    const comparisonResult = await client.action(
      "chunkingTests:compareChunkingStrategies",
      {}
    );

    if (comparisonResult.success) {
      console.log("âœ… Comparison test passed");
      console.log("ğŸ“ˆ Old vs New Chunking:");
      console.log(
        `   Old: ${comparisonResult.comparison.oldChunking.chunkCount} chunks`
      );
      console.log(
        `   New: ${comparisonResult.comparison.newChunking.chunkCount} chunks`
      );
      console.log(
        `   Improvements: ${Object.keys(comparisonResult.comparison.improvements).length} features added`
      );
    } else {
      console.log("âŒ Comparison test failed:", comparisonResult.error);
    }

    // Test 2: Enhanced chunking performance
    console.log("\nâš¡ Test 2: Enhanced Chunking Performance");
    console.log("-".repeat(40));

    const performanceResult = await client.action(
      "chunkingTests:testEnhancedChunking",
      {}
    );

    if (performanceResult.success) {
      console.log("âœ… Performance test passed");
      const results = performanceResult.testResults;
      console.log(`â±ï¸  Processing Time: ${results.processingTime}ms`);
      console.log(`ğŸ“„ Total Chunks: ${results.totalChunks}`);
      console.log(
        `âš¡ Chunks/Second: ${results.benchmarks.chunksPerSecond.toFixed(2)}`
      );
      console.log(`ğŸ“ˆ Avg Tokens/Chunk: ${results.avgTokenCount}`);
      console.log(
        `ğŸ§  Semantic Boundaries: ${results.semanticBoundaries}/${results.totalChunks} (${Math.round((results.semanticBoundaries / results.totalChunks) * 100)}%)`
      );
      console.log(
        `ğŸ”— Overlapping Chunks: ${results.overlappingChunks}/${results.totalChunks} (${Math.round((results.overlappingChunks / results.totalChunks) * 100)}%)`
      );
      console.log(
        `ğŸ’° Financial Data Chunks: ${results.financialDataChunks}/${results.totalChunks} (${Math.round((results.financialDataChunks / results.totalChunks) * 100)}%)`
      );
      console.log(
        `ğŸ¯ Quality Score: ${results.benchmarks.qualityScore.toFixed(3)}`
      );

      console.log("\nğŸ“Š Chunk Types Distribution:");
      Object.entries(results.chunkTypes).forEach(([type, count]) => {
        console.log(`   ${type}: ${count} chunks`);
      });
    } else {
      console.log("âŒ Performance test failed:", performanceResult.error);
    }

    // Test 3: Enhanced processing pipeline
    console.log("\nğŸ”„ Test 3: Enhanced Processing Pipeline");
    console.log("-".repeat(40));

    // First, create a test document
    const createDocResult = await client.mutation("documents:createDocument", {
      fileName: "test-enhanced-chunking.pdf",
      fileSize: 1024,
      mimeType: "application/pdf",
      userId: "test-user-id", // This would normally be a real user ID
    });

    if (createDocResult.success) {
      console.log("âœ… Test document created");

      // Process the document with enhanced chunking
      const processResult = await client.action(
        "enhancedProcessing:processDocumentEnhanced",
        {
          documentId: createDocResult.documentId,
        }
      );

      if (processResult.success) {
        console.log("âœ… Enhanced processing completed");
        console.log(`ğŸ“„ Chunks Created: ${processResult.chunksCreated}`);

        // Get chunking statistics
        const statsResult = await client.action(
          "enhancedProcessing:getChunkingStats",
          {
            documentId: createDocResult.documentId,
          }
        );

        if (statsResult.success) {
          console.log("ğŸ“Š Chunking Statistics:");
          console.log(`   Total Chunks: ${statsResult.totalChunks}`);
          console.log(`   Avg Token Count: ${statsResult.avgTokenCount}`);
          console.log(
            `   Semantic Boundaries: ${statsResult.semanticBoundaries}`
          );
          console.log(
            `   Overlapping Chunks: ${statsResult.overlappingChunks}`
          );
          console.log(
            `   Financial Data Chunks: ${statsResult.financialDataChunks}`
          );

          console.log("\nğŸ“ˆ Chunk Types:");
          Object.entries(statsResult.chunkTypes).forEach(([type, count]) => {
            console.log(`   ${type}: ${count}`);
          });
        } else {
          console.log("âŒ Failed to get chunking stats:", statsResult.error);
        }
      } else {
        console.log("âŒ Enhanced processing failed:", processResult.error);
      }
    } else {
      console.log("âŒ Failed to create test document:", createDocResult.error);
    }

    console.log("\nğŸ‰ All Enhanced Chunking Tests Completed!");
    console.log("âœ… Enhanced chunking implementation is working correctly");
  } catch (error) {
    console.error("âŒ Test suite failed:", error.message);
    console.error("Stack trace:", error.stack);
  }
}

// Run the test
testEnhancedChunking();
